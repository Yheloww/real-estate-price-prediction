from bs4 import BeautifulSoup
from selenium import webdriver
import pandas as pd
from csv import writer

for i in range(1, 2):
    page_num = str(i) + "&orderBy=relevance"
    city_code = ["namur","liege","brussels","antwerp","brugge","ghent","hasselt","mechelen","dinant"]

    for z in range(0,10):

        url = ("https://www.immoweb.be/en/search/house-and-apartment/for-sale/" + str(city_code[z]) +  "/province?countries=BE&page=" + page_num
        )
        list_of_properties = []

        driver = webdriver.Chrome(executable_path="driver/chromedriver")
        driver.get(url)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        listings = soup.find_all("a", class_="card__title-link")

        for pages in listings:  

            property_details = {}
            driver.get(pages["href"]) 
            property_details_page = BeautifulSoup(driver.page_source, "html.parser")

            script_list = property_details_page.find_all("script")

            details_json = "" # use to store json which contains detailed information

            for script in script_list:  # iterate all the scripts to get relevent information

                # search for the script tag which have window.dataLayer in it, This script have most 
                # of the basic details that we need.

                if "window.dataLayer" in str(script): 
                    script_content = str(script)
                    details_json = json.loads(
                        script_content[
                            script_content.index("[") : script_content.index("]") + 1
                        ]
                    )
