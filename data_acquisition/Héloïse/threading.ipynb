{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feldm\\AppData\\Local\\Temp\\ipykernel_14804\\1307570737.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"driver/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from threading import Thread\n",
    "#import for threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import RLock\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#creation of the file\n",
    "test = f\"./fullTest.json\"\n",
    "\n",
    "#need to set up the driver outside of the scraping part bc we need several drivers\n",
    "def driversetting():\n",
    "    driver = webdriver.Chrome(executable_path=\"driver/chromedriver\")\n",
    "    return driver\n",
    "\n",
    "def scraping(iteration, driver):\n",
    "    list_of_properties = []\n",
    "\n",
    "    for number in iteration:\n",
    "        page_num = str(number) + \"&orderBy=relevance\"\n",
    "        url = (\n",
    "           \"https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page=\" + page_num\n",
    "        )\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        listings = soup.find_all(\"a\", class_=\"card__title-link\")\n",
    "        for pages in listings:  \n",
    "\n",
    "            driver.get(pages[\"href\"]) # get the response from the url\n",
    "            property_details_page = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            list_of_properties.append(property_details_page)\n",
    "    return list_of_properties\n",
    "\n",
    "def saving_datas(datas):\n",
    "    with open(test, 'a') as file:\n",
    "        json.dump(str(datas), file, indent=4)\n",
    "#concurrency setting\n",
    "def pool():\n",
    "    # 1 driver by thread (we have four thread here)\n",
    "    drivers = [driversetting() for _ in range(8)]\n",
    "    #division of the number of pages by the number of threads \n",
    "    division = np.array_split(np.arange(1,300),8)\n",
    "    #creation of a pool of threads\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor :\n",
    "        bucket = executor.map(scraping,division,drivers)\n",
    "        results = [item for block in bucket for item in block]\n",
    "        saving_datas(results)\n",
    "\n",
    "pool()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immowebtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1c5e37f8ecd635be08e77ec675f54160133ad3a26aadff258a76820bf7dab8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
