{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from csv import writer\n",
    "import time \n",
    "\n",
    "for i in range(1, 20):\n",
    "    page_num = str(i) + \"&orderBy=relevance\"\n",
    "    city_code = [\"namur\",\"liege\",\"brussels\",\"antwerp\",\"brugge\",\"ghent\",\"hasselt\",\"mechelen\",\"dinant\"]\n",
    "    # this sleep line can help us to give a break before reach each the pages\n",
    "    time.sleep(\n",
    "        15\n",
    "    )  \n",
    "    for z in range(len(city_code)):\n",
    "\n",
    "        url = (\"https://www.immoweb.be/en/search/house-and-apartment/for-sale/\" + str(city_code[z]) +  \"/province?countries=BE&page=\" + page_num\n",
    "        )\n",
    "        list_of_properties = []\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path=\"driver/chromedriver\")\n",
    "        driver.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        listings = soup.find_all(\"a\", class_=\"card__title-link\")\n",
    "\n",
    "        for pages in listings:  \n",
    "\n",
    "            property_details = {}\n",
    "            driver.get(pages[\"href\"]) \n",
    "            property_details_page = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            script_list = property_details_page.find_all(\"script\")\n",
    "\n",
    "            # listing help us to find all web pages\n",
    "    listings = soup.find_all(\"a\", class_=\"card__title-link\")\n",
    "\n",
    "    # for each property we are getting the url and get the response from the url\n",
    "    for pages in listings:  \n",
    "\n",
    "        property_details = {}\n",
    "        driver.get(pages[\"href\"]) # get the response from the url\n",
    "        property_details_page = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # To scrap data from website we need to get the json file which is coming in script file as java script \n",
    "        # So to get data from script tag we list att script tags in page\n",
    "        script_list = property_details_page.find_all(\"script\")\n",
    "\n",
    "        details_json = \"\" # use to store json which contains detailed information\n",
    "\n",
    "        for script in script_list:  # iterate all the scripts to get relevent information\n",
    "\n",
    "            # search for the script tag which have window.dataLayer in it, This script have most \n",
    "            # of the basic details that we need.\n",
    "\n",
    "            if \"window.dataLayer\" in str(script): \n",
    "                script_content = str(script)\n",
    "                details_json = json.loads(\n",
    "                    script_content[\n",
    "                        script_content.index(\"[\") : script_content.index(\"]\") + 1\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # search for the script tag which have window.classified in it, This script have some more \n",
    "            # information which we not found in previous script of the basic details that we need.\n",
    "            \n",
    "            if \"window.classified\" in str(script):\n",
    "                script_content = str(script)\n",
    "                facade_count = \"\"\n",
    "                fireplace_exist = \"\"\n",
    "                isFurnished = \"\"\n",
    "                living_area = \"\"\n",
    "\n",
    "                # It was defficult to parse this string to json because of the special character's, \n",
    "                # we have use split function to get required information from string.\n",
    "                if '\"facadeCount\":' in script_content:\n",
    "                    facade_count = script_content.split('\"facadeCount\":')[1][\n",
    "                        :2\n",
    "                    ].replace(\",\", \"\")\n",
    "                if '\"fireplaceExists\":' in script_content:\n",
    "                    fireplace_exist = script_content.split('\"fireplaceExists\":')[1][\n",
    "                        :5\n",
    "                    ].replace(\",\", \"\")\n",
    "                if '\"isFurnished\":' in script_content:\n",
    "                    isFurnished = script_content.split('\"isFurnished\":')[1][:5].replace(\n",
    "                        \",\", \"\"\n",
    "                    )\n",
    "                if '\"netHabitableSurface\"' in script_content:\n",
    "                    living_area = (\n",
    "                        script_content.split('\"netHabitableSurface\":')[1]\n",
    "                    ).split(\",\")[0]\n",
    "\n",
    "        # first we take a specific html element that has the text of the locality\n",
    "        # and then we filter all the empty spaces and lines. That data is assigned into our property dataframe.\n",
    "\n",
    "        element_locality = (\n",
    "            property_details_page.find(\n",
    "                \"span\", class_=\"classified__information--address-row\"\n",
    "            )\n",
    "            .text.replace(\"\\n\", \"\")\n",
    "            .strip()\n",
    "            .replace(\"           \", \"  \")\n",
    "        )\n",
    "\n",
    "        # if the value of the locality is empty on json then we are going to assign it as a None value \n",
    "        # otherwise it will copy the actual value and this is the way we filter all the other attributes of our dataframe\n",
    "\n",
    "        property_details[\"Locality\"] = (\n",
    "            None if element_locality == \"\" else element_locality\n",
    "        )\n",
    "        property_details[\"Type_of_property\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"type\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"type\"]\n",
    "        )\n",
    "        property_details[\"Subtype_of_property\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"subtype\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"subtype\"]\n",
    "        )\n",
    "        property_details[\"Price\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"price\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"price\"]\n",
    "        )\n",
    "        property_details[\"TransactionType\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"transactionType\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"transactionType\"]\n",
    "        )\n",
    "        property_details[\"No_of_rooms\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"bedroom\"][\"count\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"bedroom\"][\"count\"]\n",
    "        )\n",
    "        property_details[\"Kitchen\"] = (\n",
    "            0 if details_json[0][\"classified\"][\"kitchen\"][\"type\"] == \"\" else 1\n",
    "        )\n",
    "        property_details[\"IsFurnished\"] = 1 if isFurnished == \"true\" else 0\n",
    "        property_details[\"Fireplace_exist\"] = 1 if fireplace_exist == \"true\" else 0\n",
    "        property_details[\"Garden\"] = (\n",
    "            1\n",
    "            if len(details_json[0][\"classified\"][\"outdoor\"][\"garden\"][\"surface\"]) != 0\n",
    "            else 0\n",
    "        )\n",
    "        property_details[\"Terrace\"] = (\n",
    "            1\n",
    "            if details_json[0][\"classified\"][\"outdoor\"][\"terrace\"][\"exists\"] == \"true\"\n",
    "            else 0\n",
    "        )\n",
    "        property_details[\"Surface_area\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"land\"][\"surface\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"land\"][\"surface\"] + \"m2\"\n",
    "        )\n",
    "        property_details[\"Living_area\"] = (\n",
    "            None if living_area == \"\" else living_area + \"m2\"\n",
    "        )\n",
    "        property_details[\"Facade_count\"] = None if facade_count == \"\" else facade_count\n",
    "        property_details[\"Swimming_pool\"] = (\n",
    "            0\n",
    "            if details_json[0][\"classified\"][\"wellnessEquipment\"][\"hasSwimmingPool\"]\n",
    "            == \"\"\n",
    "            else 1\n",
    "        )\n",
    "        property_details[\"State_of_building\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"building\"][\"condition\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"building\"][\"condition\"]\n",
    "        )\n",
    "\n",
    "        # we are going to append the specific details of a property into the lists of properties\n",
    "\n",
    "        list_of_properties.append(property_details)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"page no= \", i)\n",
    "\n",
    "    # Creating Dataframes from the list of Dictionaries\n",
    "\n",
    "    data = list_of_properties\n",
    "    df = pd.DataFrame(data)\n",
    "    df.replace(\"\", None, inplace=True)\n",
    "\n",
    "    # Saving the dataframe into a CSV file \n",
    "    # We specify mode (append) so the data will be appended into the csv file for every webpage we scrape\n",
    "\n",
    "    df.to_csv(\"property_data.csv\", mode=\"a\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# listing help us to find all web pages\n",
    "    listings = soup.find_all(\"a\", class_=\"card__title-link\")\n",
    "\n",
    "    # for each property we are getting the url and get the response from the url\n",
    "    for pages in listings:  \n",
    "\n",
    "        property_details = {}\n",
    "        driver.get(pages[\"href\"]) # get the response from the url\n",
    "        property_details_page = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # To scrap data from website we need to get the json file which is coming in script file as java script \n",
    "        # So to get data from script tag we list att script tags in page\n",
    "        script_list = property_details_page.find_all(\"script\")\n",
    "\n",
    "        details_json = \"\" # use to store json which contains detailed information\n",
    "\n",
    "        for script in script_list:  # iterate all the scripts to get relevent information\n",
    "\n",
    "            # search for the script tag which have window.dataLayer in it, This script have most \n",
    "            # of the basic details that we need.\n",
    "\n",
    "            if \"window.dataLayer\" in str(script): \n",
    "                script_content = str(script)\n",
    "                details_json = json.loads(\n",
    "                    script_content[\n",
    "                        script_content.index(\"[\") : script_content.index(\"]\") + 1\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # search for the script tag which have window.classified in it, This script have some more \n",
    "            # information which we not found in previous script of the basic details that we need.\n",
    "            \n",
    "            if \"window.classified\" in str(script):\n",
    "                script_content = str(script)\n",
    "                facade_count = \"\"\n",
    "                fireplace_exist = \"\"\n",
    "                isFurnished = \"\"\n",
    "                living_area = \"\"\n",
    "\n",
    "                # It was defficult to parse this string to json because of the special character's, \n",
    "                # we have use split function to get required information from string.\n",
    "                if '\"facadeCount\":' in script_content:\n",
    "                    facade_count = script_content.split('\"facadeCount\":')[1][\n",
    "                        :2\n",
    "                    ].replace(\",\", \"\")\n",
    "                if '\"fireplaceExists\":' in script_content:\n",
    "                    fireplace_exist = script_content.split('\"fireplaceExists\":')[1][\n",
    "                        :5\n",
    "                    ].replace(\",\", \"\")\n",
    "                if '\"isFurnished\":' in script_content:\n",
    "                    isFurnished = script_content.split('\"isFurnished\":')[1][:5].replace(\n",
    "                        \",\", \"\"\n",
    "                    )\n",
    "                if '\"netHabitableSurface\"' in script_content:\n",
    "                    living_area = (\n",
    "                        script_content.split('\"netHabitableSurface\":')[1]\n",
    "                    ).split(\",\")[0]\n",
    "\n",
    "        # first we take a specific html element that has the text of the locality\n",
    "        # and then we filter all the empty spaces and lines. That data is assigned into our property dataframe.\n",
    "\n",
    "        element_locality = (\n",
    "            property_details_page.find(\n",
    "                \"span\", class_=\"classified__information--address-row\"\n",
    "            )\n",
    "            .text.replace(\"\\n\", \"\")\n",
    "            .strip()\n",
    "            .replace(\"           \", \"  \")\n",
    "        )\n",
    "\n",
    "        # if the value of the locality is empty on json then we are going to assign it as a None value \n",
    "        # otherwise it will copy the actual value and this is the way we filter all the other attributes of our dataframe\n",
    "\n",
    "        property_details[\"Locality\"] = (\n",
    "            None if element_locality == \"\" else element_locality\n",
    "        )\n",
    "        property_details[\"Type_of_property\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"type\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"type\"]\n",
    "        )\n",
    "        property_details[\"Subtype_of_property\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"subtype\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"subtype\"]\n",
    "        )\n",
    "        property_details[\"Price\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"price\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"price\"]\n",
    "        )\n",
    "        property_details[\"TransactionType\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"transactionType\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"transactionType\"]\n",
    "        )\n",
    "        property_details[\"No_of_rooms\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"bedroom\"][\"count\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"bedroom\"][\"count\"]\n",
    "        )\n",
    "        property_details[\"Kitchen\"] = (\n",
    "            0 if details_json[0][\"classified\"][\"kitchen\"][\"type\"] == \"\" else 1\n",
    "        )\n",
    "        property_details[\"IsFurnished\"] = 1 if isFurnished == \"true\" else 0\n",
    "        property_details[\"Fireplace_exist\"] = 1 if fireplace_exist == \"true\" else 0\n",
    "        property_details[\"Garden\"] = (\n",
    "            1\n",
    "            if len(details_json[0][\"classified\"][\"outdoor\"][\"garden\"][\"surface\"]) != 0\n",
    "            else 0\n",
    "        )\n",
    "        property_details[\"Terrace\"] = (\n",
    "            1\n",
    "            if details_json[0][\"classified\"][\"outdoor\"][\"terrace\"][\"exists\"] == \"true\"\n",
    "            else 0\n",
    "        )\n",
    "        property_details[\"Surface_area\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"land\"][\"surface\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"land\"][\"surface\"] + \"m2\"\n",
    "        )\n",
    "        property_details[\"Living_area\"] = (\n",
    "            None if living_area == \"\" else living_area + \"m2\"\n",
    "        )\n",
    "        property_details[\"Facade_count\"] = None if facade_count == \"\" else facade_count\n",
    "        property_details[\"Swimming_pool\"] = (\n",
    "            0\n",
    "            if details_json[0][\"classified\"][\"wellnessEquipment\"][\"hasSwimmingPool\"]\n",
    "            == \"\"\n",
    "            else 1\n",
    "        )\n",
    "        property_details[\"State_of_building\"] = (\n",
    "            None\n",
    "            if details_json[0][\"classified\"][\"building\"][\"condition\"] == \"\"\n",
    "            else details_json[0][\"classified\"][\"building\"][\"condition\"]\n",
    "        )\n",
    "\n",
    "        # we are going to append the specific details of a property into the lists of properties\n",
    "\n",
    "        list_of_properties.append(property_details)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"page no= \", i)\n",
    "\n",
    "    # Creating Dataframes from the list of Dictionaries\n",
    "\n",
    "    data = list_of_properties\n",
    "    df = pd.DataFrame(data)\n",
    "    df.replace(\"\", None, inplace=True)\n",
    "\n",
    "    # Saving the dataframe into a CSV file \n",
    "    # We specify mode (append) so the data will be appended into the csv file for every webpage we scrape\n",
    "\n",
    "    df.to_csv(\"property_data.csv\", mode=\"a\", header=None, index=False)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
